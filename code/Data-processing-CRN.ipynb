{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ccb1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61383935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitID</th>\n",
       "      <th>weekID</th>\n",
       "      <th>outcome</th>\n",
       "      <th>treatment</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.225447</td>\n",
       "      <td>88362</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>KF7</td>\n",
       "      <td>E_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>1</td>\n",
       "      <td>534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.225447</td>\n",
       "      <td>87892</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>KF7</td>\n",
       "      <td>E_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>2</td>\n",
       "      <td>550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.225447</td>\n",
       "      <td>87358</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>KF7</td>\n",
       "      <td>E_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unitID  weekID  outcome  treatment         X1     X2  X3 C1   C2   C3\n",
       "0  UNIT01155       0      470        0.0  64.225447  88362   0  M  KF7  E_2\n",
       "1  UNIT01155       1      534        0.0  64.225447  87892   0  M  KF7  E_2\n",
       "2  UNIT01155       2      550        0.0  64.225447  87358   0  M  KF7  E_2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/training_sample.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e73faf",
   "metadata": {},
   "source": [
    "Covariates\n",
    "1. X1 - static cts\n",
    "2. X2 - temporal cts\n",
    "3. X3 - temporal binary\n",
    "4. C1 - static categorical (15 levels)\n",
    "5. C2 - (Discard) static categorical (2495 levels)\n",
    "6. C3 - static categorical (6 levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b320c93",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba5c598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unitID</th>\n",
       "      <th>weekID</th>\n",
       "      <th>outcome</th>\n",
       "      <th>treatment</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>E_2</th>\n",
       "      <th>E_3</th>\n",
       "      <th>E_4</th>\n",
       "      <th>E_5</th>\n",
       "      <th>E_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>0</td>\n",
       "      <td>6.154858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1624</td>\n",
       "      <td>11.389197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>1</td>\n",
       "      <td>6.282267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1624</td>\n",
       "      <td>11.383864</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>2</td>\n",
       "      <td>6.311735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1624</td>\n",
       "      <td>11.377770</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>3</td>\n",
       "      <td>6.333280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.1624</td>\n",
       "      <td>11.371454</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNIT01155</td>\n",
       "      <td>4</td>\n",
       "      <td>7.393878</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.1624</td>\n",
       "      <td>11.364959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unitID  weekID   outcome  treatment      X1         X2  X3  E_2  E_3  \\\n",
       "0  UNIT01155       0  6.154858        0.0  4.1624  11.389197   0    1    0   \n",
       "1  UNIT01155       1  6.282267        0.0  4.1624  11.383864   0    1    0   \n",
       "2  UNIT01155       2  6.311735        0.0  4.1624  11.377770   0    1    0   \n",
       "3  UNIT01155       3  6.333280        0.0  4.1624  11.371454   0    1    0   \n",
       "4  UNIT01155       4  7.393878        0.1  4.1624  11.364959   1    1    0   \n",
       "\n",
       "   E_4  E_5  E_6  \n",
       "0    0    0    0  \n",
       "1    0    0    0  \n",
       "2    0    0    0  \n",
       "3    0    0    0  \n",
       "4    0    0    0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.get_dummies(df[\"C3\"], drop_first=True)], axis=1).drop(\"C3\", axis=1)\n",
    "df['outcome'] = np.log(df['outcome'] + 1) # Deskew and bring to same scale as other covariates\n",
    "df['X1'] = np.log(df['X1'])\n",
    "df['X2'] = np.log(df['X2'])\n",
    "df = df.drop([\"C1\", \"C2\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fe33ec",
   "metadata": {},
   "source": [
    "# Cross-validation split (Train 80 - Val 10 -Test 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d47808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Val - Test split\n",
    "units = df['unitID'].unique()\n",
    "num_units = len(units)\n",
    "cnt_train_units = int(0.8 * num_units)\n",
    "cnt_val_units = int(0.1 * num_units)\n",
    "cnt_test_units = num_units - cnt_train_units - cnt_val_units\n",
    "\n",
    "train_units = np.random.choice(units, size=cnt_train_units, replace=False)\n",
    "val_units = np.random.choice(list(set(units)-set(train_units)), size=cnt_val_units, replace=False)\n",
    "test_units = list(set(units)-set(train_units)-set(val_units))\n",
    "\n",
    "train = df[df['unitID'].isin(train_units)].sort_values(by=['unitID', 'weekID'])\n",
    "val = df[df['unitID'].isin(val_units)].sort_values(by=['unitID', 'weekID'])\n",
    "test = df[df['unitID'].isin(test_units)].sort_values(by=['unitID', 'weekID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e49050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3126, 390, 392)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_units), len(val_units), len(test_units) # No. of units in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651b16c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296970, 37050, 37240)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test) # Size of each set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ef473",
   "metadata": {},
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8e52e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/train.csv\", index=False)\n",
    "val.to_csv(\"../data/val.csv\", index=False)\n",
    "test.to_csv(\"../data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec71bd8",
   "metadata": {},
   "source": [
    "# Data Preparation for CRN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ae36c",
   "metadata": {},
   "source": [
    "## Keys required in Dataset object\n",
    "1. current_covariates\n",
    "2. current_treatments\n",
    "3. previous_treatments\n",
    "4. outputs\n",
    "5. active_entries\n",
    "6. sequence_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fa45cc",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffde7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling parameters\n",
    "num_time_steps = 90\n",
    "num_treatments = 6\n",
    "num_outputs = 1\n",
    "horizon = 1 # Output (horizon:t)\n",
    "offset = 1 # Covariates (1:t-offset)\n",
    "input_features_enc = ['outcome', 'X1', 'X2', 'X3', 'E_2', 'E_3', 'E_4', 'E_5', 'E_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17053589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_encoder(df, num_time_steps=90):\n",
    "    df = df[df['weekID'] < num_time_steps]\n",
    "    cnt_units = df['unitID'].nunique()\n",
    "\n",
    "    current_covariates = df[input_features_enc].values.reshape(cnt_units, num_time_steps, len(input_features_enc))\n",
    "    current_covariates = current_covariates[:, :-offset, :] # (num_units, 1-94 timesteps, num_input_features)\n",
    "\n",
    "    current_treatments = pd.get_dummies(\n",
    "                            df['treatment']).values.reshape(cnt_units, num_time_steps, num_treatments)\n",
    "    current_treatments = current_treatments[:, :-offset, :] # (num_units, 1-94, 6). One-Hot-encoded treatments\n",
    "    previous_treatments = current_treatments[:, :-1, :] # (num_units, 1-93, 6)\n",
    "\n",
    "    outputs = df['outcome'].values.reshape(cnt_units, num_time_steps, num_outputs) \n",
    "    outputs = outputs[:, horizon:, :] # (num_units, 2-95 timesteps, 1)\n",
    "\n",
    "    active_entries = np.ones((cnt_units, num_time_steps-1, 1)) # Each unit has data for all time steps\n",
    "    sequence_lengths = (num_time_steps-1) * np.ones(cnt_units)\n",
    "    \n",
    "    data = {\"current_covariates\": current_covariates, \n",
    "            \"current_treatments\": current_treatments,\n",
    "            \"previous_treatments\": previous_treatments,\n",
    "            \"outputs\": outputs,\n",
    "            \"active_entries\": active_entries,\n",
    "            \"sequence_lengths\": sequence_lengths\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982a0892",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_enc = process_data_encoder(train)\n",
    "val_obj_enc = process_data_encoder(val)\n",
    "test_obj_enc = process_data_encoder(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d54e3",
   "metadata": {},
   "source": [
    "### Export pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2004b61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_enc.p', 'wb') as f:\n",
    "    pickle.dump(train_obj_enc, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/val_enc.p', 'wb') as f:\n",
    "    pickle.dump(val_obj_enc, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/test_enc.p', 'wb') as f:\n",
    "    pickle.dump(test_obj_enc, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68e81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_covariates (3126, 89, 9)\n",
      "current_treatments (3126, 89, 6)\n",
      "previous_treatments (3126, 88, 6)\n",
      "outputs (3126, 89, 1)\n",
      "active_entries (3126, 89, 1)\n",
      "sequence_lengths (3908,)\n"
     ]
    }
   ],
   "source": [
    "for k in train_obj_enc.keys():\n",
    "    print(k, train_obj_enc[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a0de9",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d580a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling parameters\n",
    "projection_horizon = 5 # Predict outcomes for next 5 time steps\n",
    "num_time_steps_dec = num_time_steps + projection_horizon # 95\n",
    "input_features_dec = ['outcome', 'X1', \n",
    "                      'E_2', 'E_3', 'E_4', 'E_5', 'E_6'] # Outcome (should be 1st variable) + Static variables\n",
    "feat_idx = [0,1,4,5,6,7,8] # Index of above features in original df (Outcome + Static)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9bed775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_val_decoder(obj_enc):\n",
    "    obj_enc['current_covariates'] = obj_enc['current_covariates'][:, :, feat_idx]\n",
    "    return obj_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf6bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_decoder(df, num_time_steps_dec=95):\n",
    "    df = df[df['weekID'] < num_time_steps_dec]\n",
    "    cnt_units = df['unitID'].nunique()\n",
    "\n",
    "    current_covariates = df[input_features_dec].values.reshape(cnt_units, num_time_steps_dec, len(input_features_dec))\n",
    "    current_covariates = current_covariates[:, :-offset, :] # (num_units, 1-94 timesteps, num_input_features)\n",
    "\n",
    "    current_treatments = pd.get_dummies(\n",
    "                            df['treatment']).values.reshape(cnt_units, num_time_steps_dec, num_treatments)\n",
    "    current_treatments = current_treatments[:, :-offset, :] # (num_units, 1-94, 6). One-Hot-encoded treatments\n",
    "    previous_treatments = current_treatments[:, :-1, :] # (num_units, 1-93, 6)\n",
    "\n",
    "    outputs = df['outcome'].values.reshape(cnt_units, num_time_steps_dec, num_outputs) \n",
    "    outputs = outputs[:, horizon:, :] # (num_units, 2-95 timesteps, 1)\n",
    "    \n",
    "    active_entries = np.ones((cnt_units, num_time_steps_dec-1, 1)) # (num_units, 94, 1)\n",
    "    active_entries[-(projection_horizon-1):] = 0\n",
    "    sequence_lengths = (num_time_steps-1) * np.ones(cnt_units) #(num_time_steps_dec-1) * np.ones(num_units)\n",
    "    \n",
    "    data = {\"current_covariates\": current_covariates, \n",
    "            \"current_treatments\": current_treatments,\n",
    "            \"previous_treatments\": previous_treatments,\n",
    "            \"outputs\": outputs,\n",
    "            \"active_entries\": active_entries,\n",
    "            \"sequence_lengths\": sequence_lengths\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6381e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_dec = process_train_val_decoder(train_obj_enc)\n",
    "val_obj_dec = process_train_val_decoder(val_obj_enc)\n",
    "test_seq_obj_dec = process_test_decoder(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed376a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_covariates (3126, 89, 7)\n",
      "current_treatments (3126, 89, 6)\n",
      "previous_treatments (3126, 88, 6)\n",
      "outputs (3126, 89, 1)\n",
      "active_entries (3126, 89, 1)\n",
      "sequence_lengths (3908,)\n"
     ]
    }
   ],
   "source": [
    "for k in train_obj_dec.keys():\n",
    "    print(k, train_obj_dec[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd52013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_covariates (392, 94, 7)\n",
      "current_treatments (392, 94, 6)\n",
      "previous_treatments (392, 93, 6)\n",
      "outputs (392, 94, 1)\n",
      "active_entries (392, 94, 1)\n",
      "sequence_lengths (3908,)\n"
     ]
    }
   ],
   "source": [
    "for k in test_seq_obj_dec.keys():\n",
    "    print(k, test_seq_obj_dec[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eda988c",
   "metadata": {},
   "source": [
    "### Export pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28d22139",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_dec.p', 'wb') as f:\n",
    "    pickle.dump(train_obj_dec, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/val_dec.p', 'wb') as f:\n",
    "    pickle.dump(val_obj_dec, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../data/test_seq_dec.p', 'wb') as f:\n",
    "    pickle.dump(test_seq_obj_dec, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5dd25",
   "metadata": {},
   "source": [
    "# Data for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3589c55",
   "metadata": {},
   "source": [
    "For each unit, we are interested in the future outcome for time steps 96-100 under 6 difference treatment plans: Treatment 0-0-0-0-0, ..., 5-5-5-5-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ea4c1",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fc49fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_obj_enc = process_data_encoder(df.sort_values(by=['unitID', 'weekID']), num_time_steps=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "10066667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_covariates (3908, 94, 9)\n",
      "current_treatments (3908, 94, 6)\n",
      "previous_treatments (3908, 93, 6)\n",
      "outputs (3908, 94, 1)\n",
      "active_entries (3908, 94, 1)\n",
      "sequence_lengths (3908,)\n"
     ]
    }
   ],
   "source": [
    "for k in inf_obj_enc.keys():\n",
    "    print(k, inf_obj_enc[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee05b3e4",
   "metadata": {},
   "source": [
    "Note that for encoder- for each unit, the output (based on time steps 1-95) is the same for each sequence of treatments. Hence axis 0 shape is 3908 (num_units). \n",
    "\n",
    "For decoder, we need to prepare data for each sequence of treatments. Hence axis 0 shape will be 3908*6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42898dd9",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "778c92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_vars = [\"X1\", \"E_2\", \"E_3\", \"E_4\", \"E_5\", \"E_6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d67ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_inference(df, num_infer_steps=5):\n",
    "    ''' Append data for next 5 time steps (96-100) for each treatment (1-6) '''\n",
    "    df_infer = pd.DataFrame()\n",
    "    units = np.sort(df['unitID'].unique())\n",
    "\n",
    "    for unit in tqdm(units):\n",
    "        unit_df = df[df['unitID'] == unit]\n",
    "        unit_info = unit_df.iloc[0]\n",
    "        \n",
    "        for treat in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]:\n",
    "            # Append info vars\n",
    "            df_temp = pd.DataFrame({\"unitID\": [unit_info[\"unitID\"]]*num_infer_steps, \n",
    "                                   \"weekID\": list(range(95, 95+num_infer_steps)),\n",
    "                                   \"treatment\": [treat] * num_infer_steps})\n",
    "            # Repeat static vars\n",
    "            for var in static_vars:\n",
    "                df_temp = pd.concat([df_temp, pd.DataFrame({var: [unit_info[var]]*num_infer_steps})], axis=1)\n",
    "            \n",
    "            # Append data for unit i (time steps 1-95) with data for treatment k (time steps 96-100)\n",
    "            df_infer = pd.concat([df_infer, unit_df.copy(), df_temp], axis=0)\n",
    "            \n",
    "    df_infer = df_infer.fillna(0)\n",
    "    return df_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd0f3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_infer_data_decoder(df, num_infer_steps=5):\n",
    "    ''' Prepare data for decoder inference '''\n",
    "    num_time_steps_inf = num_time_steps_dec + num_infer_steps # 95+5\n",
    "    cnt_units = df['unitID'].nunique() * 6 # Duplicating inference data for each treatment\n",
    "    # ^Time steps 1-99 reqd for each sequence of treatments.\n",
    "\n",
    "    current_covariates = df[input_features_dec].values.reshape(cnt_units, num_time_steps_inf, len(input_features_dec))\n",
    "    current_covariates = current_covariates[:, :-offset, :] # (num_units, 1-99 timesteps, op+_num_static_features)\n",
    "\n",
    "    current_treatments = pd.get_dummies(\n",
    "                            df['treatment']).values.reshape(cnt_units, num_time_steps_inf, num_treatments)\n",
    "    current_treatments = current_treatments[:, :-offset, :] # (num_units, 1-99, 6). One-Hot-encoded treatments\n",
    "    previous_treatments = current_treatments[:, :-1, :] # (num_units, 1-98, 6)\n",
    "\n",
    "    outputs = df['outcome'].values.reshape(cnt_units, num_time_steps_inf, num_outputs) \n",
    "    outputs = outputs[:, horizon:, :] # (num_units, 2-95 timesteps, 1)\n",
    "    \n",
    "    active_entries = np.ones((cnt_units, num_time_steps_inf-1, 1)) # (num_units, 99, 1)\n",
    "    active_entries[-(projection_horizon-1):] = 0\n",
    "    sequence_lengths = (num_time_steps_dec-1) * np.ones(cnt_units) #(num_time_steps_inf-1) * np.ones(num_units)\n",
    "    \n",
    "    data = {\"current_covariates\": current_covariates, \n",
    "            \"current_treatments\": current_treatments,\n",
    "            \"previous_treatments\": previous_treatments,\n",
    "            \"outputs\": outputs,\n",
    "            \"active_entries\": active_entries,\n",
    "            \"sequence_lengths\": sequence_lengths\n",
    "           }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d4adb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 3908/3908 [10:03<00:00,  6.48it/s]\n"
     ]
    }
   ],
   "source": [
    "df_infer = get_data_inference(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4701ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344800"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infer.to_csv(\"../data/df_infer.csv.gz\", index=False, compression=\"gzip\")\n",
    "len(df_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c6d83c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_seq_obj_dec = process_infer_data_decoder(df_infer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cb5dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_covariates (23448, 99, 7)\n",
      "current_treatments (23448, 99, 6)\n",
      "previous_treatments (23448, 98, 6)\n",
      "outputs (23448, 99, 1)\n",
      "active_entries (23448, 99, 1)\n",
      "sequence_lengths (23448,)\n"
     ]
    }
   ],
   "source": [
    "for k in inf_seq_obj_dec.keys():\n",
    "    print(k, inf_seq_obj_dec[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5908d92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23448"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unitID'].nunique() * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5171f",
   "metadata": {},
   "source": [
    "### Export pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c1c74c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/inf_enc.p', 'wb') as f:\n",
    "    pickle.dump(inf_obj_enc, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../data/inf_seq_dec.p', 'wb') as f:\n",
    "    pickle.dump(inf_seq_obj_dec, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
